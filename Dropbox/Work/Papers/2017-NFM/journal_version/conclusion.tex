\section{Conclusion}\label{sec:conclusion}

We presented a compositional falsification framework for STL specifications against CPSML models
based on a decomposition between the analysis of machine learning
components and the system containined them.
We introduced an ML
analyzer able to abstract feature spaces, approximate ML classifiers, 
and provide sets of misclassified feature vectors that can be used to drive the falsification process.
We implemented our framework and showed its effectiveness for an
autonomous driving controller using perception based on deep neural networks.

This work lays the basis for future advancements. There are several
directions for future work, both theoretical and applied. In the
remainder of this section, we describe this landscape for future work.
See~\cite{SeshiaS16} for a broader discussion of these points in
the context of the goal of verified intelligent systems.

\noindent
{\em Improvements in the ML Analyzer:} 
We intend to improve our ML Analyzer
exploring the automatic generation of feature space abstractions from given
training sets. One direction is to exploit the structure of ML
components, e.g., the custom architectures that have been
developed for deep neural networks in applications such as autonomous
driving~\cite{iandola2016squeezenet}.
For instance, one could perform a sensitivity analysis that 
indicates along which axis in the abstract
space we should move in order to change the output label or reduce
the confidence of the classifier on its output.
Another direction is to improve the sampling techniques
that we have explored so far, ideally devising one that
captures the probability of detecting a corner-case scenario leading
to a property violation. Of particular interest are adaptive sampling methods
involving further cooperation between the ML Analyzer and the CPS Analyzer. 
We are also interested in integrating other techniques
for generating misclassifications of ML components 
(e.g.,~\cite{moosavi2015deepfool,huang-arxiv16,carlini-ieeesp17})
into our approach.

\noindent
{\em Impacting the ML component design:}
Our falsification approach produces input sequences that result
in the violation of a desired property.
While this is useful, it is arguably even more useful to obtain higher-level
interpretable insight into where the training data falls short, what
new scenarios must be added to the training set, and how the 
learning algorithms' parameters must be adjusted to improve accuracy.
For example, one could use techniques for mining specifications
or requirements (e.g.,~\cite{jin-tcad15,vazquez-cav17}) 
to aggregate interesting test images or video
into a cluster that can be represented in a high-level fashion.
One could also apply our ML Analyzer outside the 
falsification context, such as for controller synthesis. 

\noindent
{\em Further Applications:}
Although our approach has shown initial promise for reasoning about
autonomous driving systems, much more remains to be done to make this
practical. Real sensor systems for autonomous driving involve multiple sensors
(cameras, LIDAR, RADAR, etc.) whose raw outputs are often fused and 
combined with deep learning or other ML techniques to
extract higher level information (such as the location and type
of objects around the vehicle). This sensor space has very high
dimensionality and high complexity, not to mention 
streams of sensor input (e.g., video), that one must be able to analyze
efficiently.
To handle industrial-scale production systems, our overall analysis
must be scaled up substantially,
potentially via use of cloud computing infrastructure.
Finally, our compositional 
methodology could be extended to other, non-cyber-physical,
systems that contain ML components.
